import { ChatOpenAI } from '@langchain/openai';
import { SqliteDataSource } from './datasources/sqlite.js';
import { DocumentDataSource } from './datasources/document.js';
import { BashDataSource } from './datasources/bash.js';
import { ToolRouter } from './router.js';
import { HumanMessage, AIMessage } from '@langchain/core/messages';
import chalk from 'chalk';

export class MultiSourceAgent {
    constructor() {
        this.llm = null;
        this.dataSources = {};
        this.router = null;
        this.conversationHistory = [];
    }

    async initialize() {
        console.log(chalk.blue('üîß Initializing Multi-Source AI Agent...'));

        // Initialize LLM
        this.llm = new ChatOpenAI({
            openAIApiKey: process.env.OPENAI_API_KEY,
            modelName: process.env.MODEL_NAME || 'gpt-4o-mini',
            temperature: parseFloat(process.env.TEMPERATURE || '0.3'),
            maxTokens: parseInt(process.env.MAX_TOKENS || '1000'),
        });

        // Initialize data sources
        console.log(chalk.gray('  üìä Initializing data sources...'));
        this.dataSources = {
            sqlite: new SqliteDataSource(),
            document: new DocumentDataSource(),
            bash: new BashDataSource(),
        };

        // Initialize each data source
        for (const [name, dataSource] of Object.entries(this.dataSources)) {
            try {
                await dataSource.initialize();
                console.log(chalk.green(`  ‚úÖ ${name} data source ready`));
            } catch (error) {
                console.warn(chalk.yellow(`  ‚ö†Ô∏è  ${name} data source failed to initialize: ${error.message}`));
            }
        }

        // Initialize router
        this.router = new ToolRouter(this.llm, this.dataSources);

        console.log(chalk.green('‚úÖ Agent initialized successfully!\\n'));
    }

    async processMessage(userInput) {
        const humanMessage = new HumanMessage(userInput);
        this.conversationHistory.push(humanMessage);

        try {
            // Step 1: Route the message
            console.log(chalk.blue('üß≠ Routing message...'));
            const route = await this.router.route(userInput);
            console.log(chalk.blue(`üéØ Selected route: ${route}`));

            let dataResult = null;

            // Step 2: Process based on route
            switch (route) {
                case 'sqlite':
                    dataResult = await this.dataSources.sqlite.query(userInput);
                    break;
                case 'document':
                    dataResult = await this.dataSources.document.search(userInput);
                    break;
                case 'bash':
                    dataResult = await this.dataSources.bash.execute(userInput);
                    break;
                case 'direct':
                    // Direct conversation, no data source needed
                    break;
                default:
                    console.warn(chalk.yellow(`Unknown route: ${route}, using direct response`));
                    break;
            }

            // Step 3: Generate response with LLM
            const response = await this.generateResponse(userInput, dataResult, route);
            
            const aiResponse = new AIMessage(response);
            this.conversationHistory.push(aiResponse);
            
            return response;
        } catch (error) {
            console.error(chalk.red('‚ùå Agent processing error:'), error.message);
            return `I'm sorry, I encountered an error while processing your request: ${error.message}`;
        }
    }

    async generateResponse(userInput, dataResult, route) {
        let prompt;

        if (route === 'direct') {
            prompt = `You are a helpful AI assistant. The user said: "${userInput}". Please respond naturally and helpfully.`;
        } else if (dataResult) {
            prompt = `User question: ${userInput}

Data retrieved from ${route} source:
${dataResult}

Please provide a comprehensive and helpful answer based on the user's question and the data found. If the data doesn't fully answer the question, say so and provide what information you can.`;
        } else {
            prompt = `The user asked: "${userInput}". I tried to find relevant data using the ${route} data source, but no results were found. Please provide a helpful response explaining that no data was found and suggest how the user might rephrase their question.`;
        }

        try {
            console.log(chalk.blue('üß† Generating response...'));
            const response = await this.llm.invoke([new HumanMessage(prompt)]);
            return response.content;
        } catch (error) {
            console.error(chalk.red('‚ùå LLM generation error:'), error.message);
            return `I apologize, but I encountered an error while generating a response: ${error.message}`;
        }
    }
}
